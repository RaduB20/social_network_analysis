{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24579e5f",
   "metadata": {},
   "source": [
    "# Analysis of the 2020 US Elections Hashtag Network\n",
    "\n",
    "Authors:\n",
    "- Radu-Andrei Bourceanu\n",
    "- Juan Arturo Abaurrea Calafell\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Social Network Analysis (SNA) allows us to model complex systems by analyzing the interactions between their components. This project applies SNA techniques to analyze the digital conversation surrounding the 2020 United States Presidential Elections.\n",
    "\n",
    "### 1.1 Dataset Description\n",
    "The analysis is based on the network file **`hashtags_cleaned.graphml`**. The dataset was collected using a snowball sampling technique starting from the hashtag **#elections2020**, capturing tweets in multiple languages.\n",
    "\n",
    "In this graph representation:\n",
    "* **Nodes:** Represent hashtags used in the dataset.\n",
    "* **Edges:** Connect two nodes if the hashtags appeared together in the same message.\n",
    "* **Weights:** The edge attribute \"weight\" represents the number of tweets in which the two hashtags appeared together.\n",
    "\n",
    "### 1.2 Objectives and Methodology\n",
    "The goal of this project is to characterize the structure of the network and extract semantic insights regarding the political discussion. Following the course methodology, the analysis is divided into three main levels:\n",
    "\n",
    "1.  **Meso-Analysis (Community Detection):**\n",
    "    * We will identify communities (groups of densely connected hashtags) to understand the different topics of discussion.\n",
    "    * We will use the **Leiden Algorithm**, a method designed to improve upon Louvain by guaranteeing well-connected communities.\n",
    "    * We will then treat these communities as independent graphs and calculate their structural similarity using **Weisfeiler-Lehman Graph Kernels**, which generate feature vectors for graph comparison (similar to a \"bag-of-words\" for graphs).\n",
    "\n",
    "2.  **Macro-Analysis (Global Structure):**\n",
    "    * To handle the complexity of the large graph, we will perform **graph contraction**, collapsing each community into a single super-node to analyze the global topology more efficiently.\n",
    "    * We will evaluate whether an overlapping community structure would be more appropriate than a non-overlapping partition.\n",
    "\n",
    "3.  **Micro-Analysis (Centrality & Prediction):**\n",
    "    * We will calculate centrality metrics (such as **Degree** and **Betweenness**) to identify \"Hubs\" (central topics) and \"Bridges\" (connectors between topics).\n",
    "    * Finally, we will apply **Link Prediction** algorithms (e.g., Jaccard, Adamic-Adar) to determine which communities have the highest probability of becoming connected in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45a2a07",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa4f4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling & Math\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Community Detection\n",
    "from cdlib import algorithms, viz, evaluation\n",
    "import leidenalg\n",
    "import community as community_louvain  # python-louvain\n",
    "\n",
    "# Graph Kernels\n",
    "\n",
    "# Configuration for clearer plots\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2d69e6",
   "metadata": {},
   "source": [
    "## Loading the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeb4a49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded successfully!\n",
      "Type: <class 'networkx.classes.graph.Graph'>\n",
      "Number of nodes: 47544\n",
      "Number of edges: 536124\n",
      "\n",
      "Example Node: ('Υστερογραφα', {})\n",
      "Example Edge: ('Υστερογραφα', 'Trump', {'weight': '14'})\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the graph\n",
    "# Ensure the file 'hashtags_cleaned.graphml' is in the same folder as your notebook\n",
    "filename = \"hashtags_cleaned.graphml\"\n",
    "\n",
    "try:\n",
    "    # We create the graph object 'G'\n",
    "    G = nx.read_graphml(filename)\n",
    "    \n",
    "    # 2. Basic verification\n",
    "    print(\"Graph loaded successfully!\")\n",
    "    print(f\"Type: {type(G)}\")\n",
    "    print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "    \n",
    "    # 3. Check node attributes (to see if hashtags are stored correctly)\n",
    "    # Print the first node and its attributes\n",
    "    first_node = list(G.nodes(data=True))[0]\n",
    "    print(f\"\\nExample Node: {first_node}\")\n",
    "    \n",
    "    # 4. Check edge attributes (looking for 'weight')\n",
    "    first_edge = list(G.edges(data=True))[0]\n",
    "    print(f\"Example Edge: {first_edge}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{filename}' was not found. Please check the path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf875f",
   "metadata": {},
   "source": [
    "## 1: Community Detection (Leiden Algorithm)\n",
    "\n",
    "In this exercise, we perform **meso-analysis** to identify communities within the hashtag network. We use the **Leiden algorithm**, which is an improvement over the Louvain method. Leiden is designed to find well-connected communities and guarantees that communities are not disconnected, a common issue with Louvain.\n",
    "\n",
    "We will:\n",
    "1.  Apply the Leiden algorithm using the edge weights (frequency of co-occurrence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eceba547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Community Detection using Leiden Algorithm ---\n",
      "Algorithm applied successfully.\n",
      "Total detected communities: [63]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Community Detection using Leiden Algorithm ---\")\n",
    "leiden_coms = algorithms.leiden(G).to_node_community_map()\n",
    "print(\"Algorithm applied successfully.\")\n",
    "\n",
    "coms = {k:v for k,v in leiden_coms.items()}\n",
    "\n",
    "print(f\"Total detected communities: {max(coms.values())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sna_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
